{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RP-Open.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Unh4OybA10VP",
        "3ciQwuqGifkQ",
        "tCzX0_3-LTUc",
        "tCIDazkhgL0x",
        "dj_0Q0AJvRle",
        "Brd8YqZDvcCH",
        "Ee59bZINmiJ6"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSYysaZV5xQtuuxyz+/cQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhizarAziz/RP/blob/master/RP_Open.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLdQBPezxR0h"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_reo17cn28yK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "import math\n",
        "import dlib\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.login()\n",
        "#import fastai.vision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooBWthjcla3r"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + '0dev_folder/Data/'\n",
        "colab_base_dir = '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPh9CBIAs8B1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unh4OybA10VP"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Github`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8u1jqLBeX9_"
      },
      "source": [
        "!git clone https://github.com/KhizarAziz/RP.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ciQwuqGifkQ"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Download Datasets and Code`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GSs3j6hIOyM"
      },
      "source": [
        "#download imdb\n",
        "# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
        "#download WIKI\n",
        "# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V57knmyIvI-Q"
      },
      "source": [
        "#extract datasets\n",
        "# !tar -xvf imdb_crop.tar -C /content/RP/dataset\n",
        "# !tar -xvf wiki_crop.tar -C /content/RP/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCzX0_3-LTUc"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Preprocess Datasets`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV8SazL4Iitv"
      },
      "source": [
        "cd /content/RP/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nTHmnm6Nki5"
      },
      "source": [
        "#Wiki-IDMB\n",
        "# !python /content/RP/m_preprocess_dataset/pre_process_WIKI-IMDB.py\n",
        "#Morph\n",
        "#!python /content/RP/m_preprocess_dataset/pre_process_Morph.py\n",
        "#FGNET\n",
        "# !python /content/RP/m_preprocess_dataset/pre_process_FGNET.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCIDazkhgL0x"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Train`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH0kCE6YCcQ"
      },
      "source": [
        "cd /content/RP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g56nhDyAKhSN"
      },
      "source": [
        "import math\n",
        "from m_net_training import C3AE_net\n",
        "from m_net_training import training_utils\n",
        "import feather\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
        "from keras.losses import kl_divergence,MAE\n",
        "from keras.metrics import mae,Accuracy\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKwHNiopvjKu"
      },
      "source": [
        "# initialize wandb with your project name and optionally with configutations.\n",
        "category = 12\n",
        "interval = 10\n",
        "run = wandb.init(project='My-Project',\n",
        "           config={\n",
        "              \"Age_Loss\": 'mean_absolute_error',\n",
        "              \"CLR_METHOD\": 'triangular',\n",
        "              \"MAX_LR\": 0.01,\n",
        "              \"MIN_LR\": 1.000e-7,\n",
        "              \"NUM_EPOCHS\": 70,\n",
        "              \"STEP_SIZE\": 7,\n",
        "              \"W1_Loss\": 'kl_divergence',\n",
        "              'architecture':'architecture??',\n",
        "              'batch_size':64,\n",
        "              'dataset':'wiki',\n",
        "              'dropout':0.2,\n",
        "              'img_ch':3,\n",
        "              'img_h':64,\n",
        "              'img_w':64,\n",
        "              'random_enforcing':False,\n",
        "              'random_erasing':False,\n",
        "              'seed':2021,\n",
        "              'test_split':0.2,\n",
        "              'train_split':0.8,\n",
        "              'use_SE_block':True,\n",
        "              'use_white_norm':True\n",
        "           })\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56dzAkRZu5xT"
      },
      "source": [
        "# Loading dataset (from .feather file)\n",
        "dataset_dir = Path(f'/content/RP/dataset/{config.dataset}_crop')\n",
        "dataset_df = pd.DataFrame(columns=[\"image_path\",\"age\", \"gender\", \"image\", \"org_box\", \"landmarks\"])\n",
        "for fnames in dataset_dir.glob('*.feather'):\n",
        "  df_chunk = feather.read_dataframe(dataset_dir.joinpath(fnames))\n",
        "  dataset_df = pd.concat([dataset_df,df_chunk],ignore_index=True)\n",
        "dataset_df = dataset_df.astype({'age': 'float64'})\n",
        "dataset_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j71HUXvy3hb2"
      },
      "source": [
        "trainset, testset = train_test_split(dataset_df, train_size=config.train_split, test_size=config.test_split, random_state=config.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CawtVR3swp"
      },
      "source": [
        "input_shape = (config.img_h,config.img_w)\n",
        "train_gen =     training_utils.img_and_age_data_generator(trainset,batch_size=config.batch_size,category=category,interval=interval,imgs_shape=input_shape,random_erasing=config.random_erasing,random_enforcing=config.random_enforcing,dropout=config.dropout)\n",
        "validation_gen = training_utils.img_and_age_data_generator(testset,batch_size=config.batch_size,category=category,interval=interval,imgs_shape=input_shape,random_erasing=False,random_enforcing=False,dropout=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0mFDC5kK4i8"
      },
      "source": [
        "index = 1\n",
        "first_batch = next(iter(train_gen))\n",
        "print(type(first_batch[1][0]),type(first_batch[1][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJiYgCuepDYK"
      },
      "source": [
        "index += 1\n",
        "Accepted_List = [first_batch[0][0][index],first_batch[0][1][index],first_batch[0][2][index]]\n",
        "print(first_batch[1][0][index])\n",
        "f,axarr = plt.subplots(nrows=1,ncols=3,figsize=(10,10))\n",
        "for i in range(3):\n",
        "    img = Accepted_List[i]\n",
        "    axarr[i].imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdsEkqRAodzs"
      },
      "source": [
        "age_distribution = [trainset[\"age\"][(trainset.age >= x -10) & (trainset.age <= x)].count() for x in range(10, 101, 10)]\n",
        "age_distribution = [age_distribution[0]] + age_distribution + [age_distribution[-1]]\n",
        "print(age_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxrdUhbqq7kj"
      },
      "source": [
        "import imp\n",
        "imp.reload(C3AE_net)\n",
        "tf.keras.backend.clear_session()\n",
        "model = C3AE_net.build_model(Categories = category, using_SE=config.use_SE_block, using_white_norm=config.use_white_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj_0Q0AJvRle"
      },
      "source": [
        "### **`Compile_model`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6_b6GXXaCyO"
      },
      "source": [
        "adam = Adam(lr=config.MIN_LR)\n",
        "weight_factor = 10\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    loss = {'W1':config.W1_Loss,'age':config.Age_Loss},\n",
        "    metrics={\"age\": mae,\"W1\":'accuracy'},\n",
        "    loss_weights={'W1':weight_factor, 'age': 1}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmdWv3XIXt4j"
      },
      "source": [
        "class meriApniCustom_lr_history(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self,epoch, logs={}):\n",
        "      lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "      print('our lr is: {} '.format(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8o0_6DCFILB"
      },
      "source": [
        "save_path = '/content/RP/m_models_saved/morph-'\n",
        "callbacks = [\n",
        "  ModelCheckpoint(save_path+'weights.{epoch:02d}-{val_age_mean_absolute_error:.2f}.hdf5',\n",
        "                  monitor='val_age_mean_absolute_error',\n",
        "                  verbose = 1,\n",
        "                  save_best_only=True,\n",
        "                  model ='min'),\n",
        " \n",
        "  training_utils.CyclicLR(\n",
        "                    mode=config.CLR_METHOD,\n",
        "                    base_lr=config.MIN_LR,\n",
        "                    max_lr=config.MAX_LR,\n",
        "                    step_size=config.STEP_SIZE * (trainset.shape[0] // config.batch_size)),\n",
        "  meriApniCustom_lr_history(),\n",
        " \n",
        "  WandbCallback(monitor='val_age_loss')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brd8YqZDvcCH"
      },
      "source": [
        "### **`Fit`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qqE8sbYAC66"
      },
      "source": [
        "history = model.fit(train_gen, steps_per_epoch=len(trainset) / config.batch_size, epochs=config.NUM_EPOCHS, callbacks=callbacks, validation_data=validation_gen, validation_steps=len(testset) / config.batch_size * 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee59bZINmiJ6"
      },
      "source": [
        "\n",
        "\n",
        "> ## **`Inference`**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a03aPpVhoOKh"
      },
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/C3AE/detect/shape_predictor_68_face_landmarks.dat\")\n",
        "def gen_face(image):\n",
        "  face_rect_list = detector(image)\n",
        "  xmin, ymin, xmax, ymax = face_rect_list[0].left() , face_rect_list[0].top(), face_rect_list[0].right(), face_rect_list[0].bottom() # face_rect is dlib.rectangle object, so extracting values from it\n",
        "  lmarks_list = dlib.full_object_detections()\n",
        "  for face_rect in face_rect_list:\n",
        "    lmarks_list.append(predictor(image, face_rect))\n",
        "  return np.array([xmin, ymin, xmax, ymax]), lmarks_list\n",
        "\n",
        "# algorithm is not finalized, as i am still in research phase.... but workable code\n",
        "\n",
        "def gen_boundbox(box, landmark):\n",
        "    xmin, ymin, xmax, ymax = box \n",
        "    w, h = xmax - xmin, ymax - ymin\n",
        "    nose_x, nose_y = (landmark.parts()[30].x, landmark.parts()[30].y)\n",
        "    w_h_margin = abs(w - h)\n",
        "    top2nose = nose_y - ymin\n",
        "\n",
        "    return np.array([\n",
        "        [(xmin - w_h_margin, ymin - w_h_margin), (xmax + w_h_margin, ymax + w_h_margin)],  # out\n",
        "        [(nose_x - top2nose, nose_y - top2nose), (nose_x + top2nose, nose_y + top2nose)],  # middle\n",
        "        [(nose_x - w//2, nose_y - w//2), (nose_x + w//2, nose_y + w//2)]  # inner box\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um60VY96mkLj"
      },
      "source": [
        "img = cv2.imread('/content/test.jpg')\n",
        "model = models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqMvA2s4n2xP"
      },
      "source": [
        "try:\n",
        "    bounds, lmarks = gen_face(img)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "padding = 200\n",
        "cv2.copyMakeBorder(img, padding, padding, padding, padding, cv2.BORDER_CONSTANT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGw3Ubc0qenf"
      },
      "source": [
        "for pidx,landmarks in enumerate(lmarks):\n",
        "    trible_box = gen_boundbox(bounds, landmarks)\n",
        "    tri_imgs = []\n",
        "    for bbox in trible_box:\n",
        "        bbox = bbox #+ padding\n",
        "        h_min, w_min = bbox[0]\n",
        "        h_max, w_max = bbox[1]\n",
        "        tri_imgs.append(cv2.resize(new_bd_img[w_min:w_max, h_min:h_max], (64, 64)))\n",
        "    print(np.array(tri_imgs).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk51n4GP9eW7"
      },
      "source": [
        "testing_imgs = []\n",
        "for img in tri_imgs:\n",
        "  new_img = np.expand_dims(img,axis=0)\n",
        "  testing_imgs.append(new_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uFSLGqcsRW4"
      },
      "source": [
        "result = models.predict(testing_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVBYlz4m2ON-"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tazYWqvB1DbF"
      },
      "source": [
        "img = tri_imgs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuP7CQ551FrU"
      },
      "source": [
        "a = np.expand_dims(img,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}